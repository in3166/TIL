## HDFS 사용자 커멘드

- 데이터 디렉토리 생성: hadoop fs -mkdir /tmp/hive
- 리스트 보기: hadoop fs -ls /
- 데이터 넣기
  ```
  hadoop fs -mkdir -p "/home/in/hadoop1/test/"
  hadoop fs -put LISENCE.txt /home/in/hadoop1/test/
  hadoop fs -ls -h /home/in/hadoop1/test/
  ```
  
 - 로컬pc -> hadoop으로 복사: hadoop fs -copyFromLocal <localsrc> <hdfs destination>
 - hadoop -> 로컬: hadoop fs -get <src> <localdest>
 - 하둡 파일 내용 보기: hadoop fs -cat /path_to_file_in_hdfs |  hadoop fs -text /sample
 - 하둡 내 데이터 삭제:  hadoop fs -mv <src> <dest> 
 - 하둡 데이토 복제:  hadoop fs -cp <src> <dest>
  
 - replication 관리:  hadoop fs -setrep <rep> <path>
  ```
   hadoop fs -setrep 2 /newdata/sample
   - 해당 경로의 모든 데이터는 replication 2로 namenode가 관리
  ```
  
  - 파일 merge:  hadoop fs -getmerge <src> <localdest>
  
  ## HDFS 세이프 모드
  - 데이터 노드를 수정할 수 없는 상태
  - 데이터 노드 중 문제 상태(미싱 블록-Replication이 0인 경우)가 많은 경우 세이프모드에 들어감
  - 읽기 전용
  
  ## 커럽트 블록
  - 파일 자체가 깨짐
  - 유실 발생 경우 파일을 지우고 원본은 다시 하둡에 넣어줘야 함
  
  ## HDFS 휴지통 설정 및 명령어
  - 데이터 삭제 시 영구적 삭제하지 않도록 휴지통 설정
  - fs.trash.interval: 체크포인트를 삭제하는 시간 간격(분), 0이면 휴지통 기능 끔
  - fs.trash.checkpoint.interval: 체크포인트 확인 간격(분), 유효기간이 지난 체크포인트 삭제
  
  - core-site.xml 설정
  ```
  <property>
    <name>fs.trash.interval</name>
    <value>1440</value>
   </property>
   <property>
    <name>fs.trash.checkpoint.interval</name>
    <value>120</value>
   </property>
  ```
  
  - 명령어
  ```
  hadoop fs -expunge   // 휴지통 비움
  hadoop fs -rm -skipTrash /user/in/file   // 휴지통 이용하지 않고 삭제
  ```
  
  
 <img src="https://github.com/in3166/TIL/blob/main/Hadoop/3.JPG" width="90%">
 - 리포트 작성 명령어: hdfs dfsadmin -report
 - 디렉토리의 용량 Quota 설정: dfsadmin -setQuota
 <br/><br/>
 
 ## HDFS Balancers
 - 하둡 운영 중 다른 스펙의 데이터노드를 하나의 클러스터로 구성
 - 노드 간 디스크 크기가 다르거나 전체 데이터 밸런싱이 되지 않는 문제 발생 가능
 - 신규 데이터 노드를 추가하는 경우에도 발생 가능
   - 이 경우 NameNode 에서 데이터 적재량이 적은 노드를 우선적으로 선정하여 block을 추가, 이 때 특정 노드 부하 몰릴 수 있음.
 
